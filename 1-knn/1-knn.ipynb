{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3821cda5",
   "metadata": {},
   "source": [
    "# Assignment 1: $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53730e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import typing as ty\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier as RefKNeighborsClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(0x0d000721)\n",
    "\n",
    "DPI = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02e58d",
   "metadata": {},
   "source": [
    "## 1. Algorithm\n",
    "\n",
    "```plain-text\n",
    "function k_nearest_neighbors(x, samples, k, distance)\n",
    "    dists <- sorted([distance(x, e) for e in samples])\n",
    "    neighbors <- first k samples with closest distances\n",
    "    return dominating label within neighbors\n",
    "endfunction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_knn(\n",
    "    x: np.ndarray,\n",
    "    samples: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    n_labels: int,\n",
    "    k: int,\n",
    ") -> tuple[int, np.ndarray]:\n",
    "    dists = np.linalg.norm(samples - x, ord=2, axis=1)\n",
    "    kni = np.argsort(dists)[:k]\n",
    "    counts = np.bincount(labels[kni], minlength=n_labels)\n",
    "    return int(np.argmax(counts)), (counts / k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6fd0c0",
   "metadata": {},
   "source": [
    "## 2. Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50fac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"../dataset/mnist.npz\") as mnist:\n",
    "    x_train, y_train = mnist[\"x_train\"], mnist[\"y_train\"]\n",
    "    x_test, y_test = mnist[\"x_test\"], mnist[\"y_test\"]\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], -1)).astype(np.float32) / 255.0\n",
    "y_train = y_train.astype(np.intp)\n",
    "x_test = x_test.reshape((x_test.shape[0], -1)).astype(np.float32) / 255.0\n",
    "y_test = y_test.astype(np.intp)\n",
    "\n",
    "print(f\"x_train.shape: {x_train.shape} dtype={x_train.dtype}\")\n",
    "print(f\"y_train.shape: {y_train.shape} dtype={y_train.dtype}\")\n",
    "print(f\"x_test.shape: {x_test.shape} dtype={x_test.dtype}\")\n",
    "print(f\"y_test.shape: {y_test.shape} dtype={y_test.dtype}\")\n",
    "\n",
    "n_labels = max(int(y_train.max()), int(y_test.max())) + 1\n",
    "print(f\"n_labels = {n_labels}\")\n",
    "assert n_labels == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da86de",
   "metadata": {},
   "source": [
    "## 3. Verification\n",
    "\n",
    "We use the `KNeighborsClassifier` provided by scikit-learn as the reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VERIF = 100\n",
    "\n",
    "verif_samples = x_test[np.random.choice(x_test.shape[0], size=N_VERIF, replace=False)]\n",
    "classifier = RefKNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)\n",
    "classifier.fit(x_train, y_train)\n",
    "for sample in tqdm(verif_samples):\n",
    "    sample = sample[np.newaxis, :]\n",
    "    pred_ref = classifier.predict(sample).squeeze(0)\n",
    "    pred_ref_prob = classifier.predict_proba(sample).squeeze(0)\n",
    "    pred_uut, pred_uut_prob = naive_knn(sample[0], x_train, y_train, 10, 5)\n",
    "    assert pred_ref == pred_uut, f\"pred_ref={pred_ref}, pred_uut={pred_uut}\"\n",
    "    assert np.allclose(\n",
    "        pred_ref_prob, pred_uut_prob\n",
    "    ), f\"pred_ref_prob={pred_ref_prob}, pred_uut_prob={pred_uut_prob}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05aae61",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "For prediction performance, we evaluate combinations of:\n",
    "\n",
    "* Different values for $k$\n",
    "* With or without feature extraction\n",
    "\n",
    "For runtime efficiency, we evaluate how dimensionality of the sample vector influence performance.\n",
    "\n",
    "We use the following metrics for binary prediction evaluation:\n",
    "\n",
    "* Accuracy $C$, recall rate $R$, precision $P$\n",
    "* $F_1$ score\n",
    "* ROC curve and AUC\n",
    "\n",
    "We then evaluate multi-class prediction by $R$ and $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3aa293",
   "metadata": {},
   "source": [
    "### 4.1. $k$'s influence on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_against_k: list[tuple[int, float]] = []\n",
    "for k in tqdm(range(1, 100, 2)):\n",
    "    classifier = RefKNeighborsClassifier(n_neighbors=k, metric=\"minkowski\", p=2)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    neighbors = classifier.predict(x_test)\n",
    "    correct = neighbors == y_test\n",
    "    c_against_k.append((k, correct.sum() / x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(dpi=DPI)\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "fac_vec = [k for k, _ in c_against_k]\n",
    "c_vec = [c for _, c in c_against_k]\n",
    "c_max, c_min = max(c_vec), min(c_vec)\n",
    "ax.plot(fac_vec, c_vec, marker=\"o\", linestyle=\"-\", color=\"blue\", markersize=4)\n",
    "ax.set_ylim(top=min(1.0, c_max + 0.001), bottom=max(0.0, c_min - 0.001))\n",
    "ax.set_xlabel(\"Number of neighbors ($k$)\", fontsize=12)\n",
    "ax.set_ylabel(\"Accuracy ($C$)\", fontsize=12)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d69df7",
   "metadata": {},
   "source": [
    "### 4.2. Feature extraction with PCA\n",
    "\n",
    "We use Principal Component Analysis tool provided by scikit-learn to reduce the dimensionality of the sample vector. We use $k=3$ here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653284b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "orig_n_dims = x_train.shape[1]\n",
    "assert x_test.shape[1] == orig_n_dims\n",
    "\n",
    "fac_acc: list[tuple[int, float]] = []\n",
    "for fac in tqdm(range(1, 32)):\n",
    "    n_dims = orig_n_dims // fac\n",
    "    pca = PCA(n_components=n_dims)\n",
    "    x_train_pca = pca.fit_transform(x_train)\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "    classifier = RefKNeighborsClassifier(n_neighbors=K, metric=\"minkowski\", p=2)\n",
    "    classifier.fit(x_train_pca, y_train)\n",
    "    neighbors = classifier.predict(x_test_pca)\n",
    "    correct = neighbors == y_test\n",
    "    accuracy = correct.sum() / x_test.shape[0]\n",
    "    fac_acc.append((fac, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ba1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(dpi=DPI)\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "fac_vec = [fac for fac, _ in fac_acc]\n",
    "c_vec = [c for _, c in fac_acc]\n",
    "c_max, c_min = max(c_vec), min(c_vec)\n",
    "ax.plot(fac_vec, c_vec, marker=\"o\", linestyle=\"-\", color=\"blue\", markersize=4)\n",
    "ax.set_ylim(top=min(1.0, c_max + 0.001), bottom=max(0.0, c_min - 0.001))\n",
    "ax.set_xlabel(\"Reduction factor\", fontsize=12)\n",
    "ax.set_ylabel(\"Accuracy ($C$)\", fontsize=12)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f033cd71",
   "metadata": {},
   "source": [
    "### 4.3. Binary prediction characteristics\n",
    "\n",
    "We choose labels \"6\" and \"9\" for the following evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = (6, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613b9e3",
   "metadata": {},
   "source": [
    "#### 4.3.1. $C$, $P$ and $R$ when $k=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "\n",
    "class BinPredEvalResult(ty.NamedTuple):\n",
    "    tp: int\n",
    "    fp: int\n",
    "    tn: int\n",
    "    fn: int\n",
    "\n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        return (self.tp + self.tn) / (self.tp + self.fp + self.tn + self.fn)\n",
    "\n",
    "    @property\n",
    "    def recall(self) -> float:\n",
    "        return self.tp / (self.tp + self.fn) if (self.tp + self.fn) > 0 else 0.0\n",
    "\n",
    "    @property\n",
    "    def precision(self) -> float:\n",
    "        return self.tp / (self.tp + self.fp) if (self.tp + self.fp) > 0 else 0.0\n",
    "\n",
    "    @property\n",
    "    def f1_score(self) -> float:\n",
    "        prec = self.precision\n",
    "        rec = self.recall\n",
    "        return 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "\n",
    "\n",
    "x_train_bin = {label: x_train.copy() for label in LABELS}\n",
    "y_train_bin = {label: (y_train == label).astype(y_train.dtype) for label in LABELS}\n",
    "x_test_bin = {label: x_test.copy() for label in LABELS}\n",
    "y_test_bin = {label: (y_test == label).astype(y_test.dtype) for label in LABELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a27fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bin: dict[int, BinPredEvalResult] = {}\n",
    "for label in tqdm(LABELS):\n",
    "    classifier = RefKNeighborsClassifier(n_neighbors=K, metric=\"minkowski\", p=2)\n",
    "    classifier.fit(x_train_bin[label], y_train_bin[label])\n",
    "    neighbors = classifier.predict(x_test_bin[label])\n",
    "    correct = neighbors == y_test_bin[label]\n",
    "    accuracy = correct.sum() / x_test_bin[label].shape[0]\n",
    "    tp = np.logical_and(neighbors == 1, y_test_bin[label] == 1).sum()\n",
    "    fp = np.logical_and(neighbors == 1, y_test_bin[label] == 0).sum()\n",
    "    tn = np.logical_and(neighbors == 0, y_test_bin[label] == 0).sum()\n",
    "    fn = np.logical_and(neighbors == 0, y_test_bin[label] == 1).sum()\n",
    "    result = BinPredEvalResult(tp=tp, fp=fp, tn=tn, fn=fn)\n",
    "    pred_bin[label] = result\n",
    "    print(\n",
    "        f'Label \"{label}\":\\tC={result.accuracy:.4f}\\tR={result.recall:.4f}\\tP={result.precision:.4f}\\tF1={result.f1_score:.4f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b477d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, dpi=DPI)\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    result = pred_bin[label]\n",
    "    cm = np.array([[result.tp, result.fn], [result.fp, result.tn]])\n",
    "    cm_scaled = np.log(cm + 1)\n",
    "    im = ax[i].imshow(cm_scaled, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "\n",
    "    thresh = cm_scaled.max() / 2\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            ax[i].text(\n",
    "                k,\n",
    "                j,\n",
    "                f\"{cm[j, k]}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if cm_scaled[j, k] > thresh else \"black\",\n",
    "            )\n",
    "\n",
    "    ax[i].set_title(f'Label \"{label}\"')\n",
    "    ax[i].set_xticks([0, 1])\n",
    "    ax[i].set_yticks([0, 1])\n",
    "    ax[i].set_xticklabels([\"1\", \"0\"])\n",
    "    ax[i].set_yticklabels([\"1\", \"0\"])\n",
    "    ax[i].set_xlabel(\"Prediction\")\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"Truth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90755588",
   "metadata": {},
   "source": [
    "#### 4.3.2. P-vs-R curve, ROC, and its AUC when $k=31$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 31\n",
    "\n",
    "conf_bin: dict[int, npt.NDArray[np.float32]] = {}\n",
    "for label in tqdm(LABELS):\n",
    "    classifier = RefKNeighborsClassifier(n_neighbors=K, metric=\"minkowski\", p=2)\n",
    "    classifier.fit(x_train_bin[label], y_train_bin[label])\n",
    "\n",
    "    pred = classifier.predict(x_test_bin[label])\n",
    "    neighbors = classifier.kneighbors(x_test_bin[label], return_distance=False)\n",
    "    assert isinstance(neighbors, np.ndarray)\n",
    "    assert neighbors.shape == (x_test_bin[label].shape[0], K)\n",
    "\n",
    "    confidences = np.zeros((x_test_bin[label].shape[0],), dtype=np.float32)\n",
    "    for i in range(x_test_bin[label].shape[0]):\n",
    "        counts = np.bincount(y_train_bin[label][neighbors[i]], minlength=2)\n",
    "        confidences[i] = counts[1] / K\n",
    "    assert np.all(confidences >= 0.0) and np.all(confidences <= 1.0)\n",
    "\n",
    "    conf_bin[label] = confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2882073",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 101\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, dpi=DPI)\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    y_true = y_test_bin[label]\n",
    "    y_scores = conf_bin[label]\n",
    "    p = y_true.sum()\n",
    "    n = y_true.shape[0] - p\n",
    "    thresholds = np.linspace(-0.001, 1.001, num=N_STEPS, endpoint=True)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for j, thr in enumerate(thresholds):\n",
    "        y_pred = (y_scores >= thr).astype(y_true.dtype)\n",
    "        tp = np.logical_and(y_pred == 1, y_true == 1).sum()\n",
    "        fp = np.logical_and(y_pred == 1, y_true == 0).sum()\n",
    "        tpr.append(tp / p if p > 0 else 0.0)\n",
    "        fpr.append(fp / n if n > 0 else 0.0)\n",
    "    tpr = np.array(tpr, dtype=np.float32)\n",
    "    fpr = np.array(fpr, dtype=np.float32)\n",
    "\n",
    "    print(f\"Label {label}:\\tAUC = {-np.trapezoid(tpr, fpr):.4f}\")\n",
    "\n",
    "    ax[i].plot(fpr, tpr, linestyle=\"-\", color=\"blue\")\n",
    "    ax[i].set_title(f'Label \"{label}\"')\n",
    "    ax[i].grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    ax[i].set_xlim(left=0.0, right=1.0)\n",
    "    ax[i].set_ylim(bottom=0.0, top=1.0)\n",
    "    ax[i].set_xlabel(\"FPR\")\n",
    "    ax[i].set_aspect(\"equal\", adjustable=\"box\")\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"TPR\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 101\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, dpi=DPI)\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    y_true = y_test_bin[label]\n",
    "    y_scores = conf_bin[label]\n",
    "    p = y_true.sum()\n",
    "    n = y_true.shape[0] - p\n",
    "    thresholds = np.linspace(-0.001, 1.001, num=N_STEPS, endpoint=True)\n",
    "    recall = []\n",
    "    prec = []\n",
    "    for j, thr in enumerate(thresholds):\n",
    "        y_pred = (y_scores >= thr).astype(y_true.dtype)\n",
    "        tp = np.logical_and(y_pred == 1, y_true == 1).sum()\n",
    "        fp = np.logical_and(y_pred == 1, y_true == 0).sum()\n",
    "        tn = np.logical_and(y_pred == 0, y_true == 0).sum()\n",
    "        fn = np.logical_and(y_pred == 0, y_true == 1).sum()\n",
    "        result = BinPredEvalResult(tp=tp, fp=fp, tn=tn, fn=fn)\n",
    "        recall.append(result.recall)\n",
    "        prec.append(result.precision)\n",
    "    recall = np.array(recall, dtype=np.float32)\n",
    "    prec = np.array(prec, dtype=np.float32)\n",
    "\n",
    "    print(f\"Label {label}:\\tAUC = {-np.trapezoid(tpr, fpr):.4f}\")\n",
    "\n",
    "    ax[i].plot(recall, prec, linestyle=\"-\", color=\"blue\")\n",
    "    ax[i].set_title(f'Label \"{label}\"')\n",
    "    ax[i].grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    ax[i].set_xlim(left=0.0, right=1.0)\n",
    "    ax[i].set_ylim(bottom=0.0, top=1.0)\n",
    "    ax[i].set_xlabel(\"Recall\")\n",
    "    ax[i].set_aspect(\"equal\", adjustable=\"box\")\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel(\"Precision\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf14a6c",
   "metadata": {},
   "source": [
    "### 4.4. Multi-class prediction characteristics\n",
    "\n",
    "We assume $k=3$ in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "classifier = RefKNeighborsClassifier(n_neighbors=K, metric=\"minkowski\", p=2)\n",
    "classifier.fit(x_train, y_train)\n",
    "pred_nary = classifier.predict(x_test)\n",
    "\n",
    "cm_nary = np.zeros((n_labels, n_labels), dtype=np.int32)\n",
    "\n",
    "for true_label, pred_label in zip(y_test, pred_nary):\n",
    "    cm_nary[true_label, pred_label] += 1\n",
    "\n",
    "for i in range(n_labels):\n",
    "    tp = cm_nary[i, i]\n",
    "    fp = cm_nary[:, i].sum() - tp\n",
    "    fn = cm_nary[i, :].sum() - tp\n",
    "    tn = cm_nary.sum() - (tp + fp + fn)\n",
    "    result = BinPredEvalResult(tp=tp, fp=fp, tn=tn, fn=fn)\n",
    "    print(\n",
    "        f\"Label {i}:\\tC={result.accuracy:.4f}\\tR={result.recall:.4f}\\tP={result.precision:.4f}\\tF1={result.f1_score:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad530754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "fig, ax = plt.subplots(dpi=DPI)\n",
    "fig.canvas.header_visible = False\n",
    "\n",
    "cm_nary_scaled = np.log(cm_nary + 1)\n",
    "\n",
    "im = ax.imshow(cm_nary_scaled, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "\n",
    "thresh = cm_nary_scaled.max() / 2\n",
    "for i in range(n_labels):\n",
    "    for j in range(n_labels):\n",
    "        ax.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{cm_nary[i, j]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if cm_nary_scaled[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "ax.set_xticks(list(range(n_labels)))\n",
    "ax.set_yticks(list(range(n_labels)))\n",
    "ax.set_xticklabels([f'\"{i}\"' for i in range(n_labels)])\n",
    "ax.set_yticklabels([f'\"{i}\"' for i in range(n_labels)])\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Truth\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
